==== To Remember ====

- Ensemble methods (Random Subspaces) might be super interesting to test out for the 1st dataset, training different classifiers for different
features (since our features are naturally separated) !!!!!

- For feature selection:
    * select classifiers for baseline
    * use feature selection keeping k best features along to the criteria
    * vary k and see when the performance starts lowering

- If we use PCA for dimensionality reduction we should talk in the report about the possibility of generalization error,
    which requires extra calculations which we decided not to no. (Remember elbow plot for PCA)
    == THEY DO WANT US TO APPLY PCA! == EVALUATING SOME MEASURES OVER SEVERAL NUMBER OF Ks (probably in clustering)

- DT prunning needed ?



Kmeans
inertia
- sem feat select: lado a lado silhoute 
- com feat select:
DBSCAN
elbow
- com feat select: elbow graph, silhouete, n_clusers
- sem feat select:

pca view dos melhores lado a lado
